{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%reload_ext autoreload\n",
    "import sys\n",
    "sys.path.append('/Users/fjgreco/Dev-Atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "transcript_dir='./CC_TRANSCRIPTS2'\n",
    "\n",
    "from preprocess import create_train_set\n",
    "\n",
    "train_set , od=create_train_set(transcript_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(train_set)  #finds the tfidf score with normalization\n",
    "cosine_scores = cosine_similarity(tfidf_matrix_train, tfidf_matrix_train)\n",
    "# [n:m] controls what document[s] are  compared to. Comparison values are stored as lists in a list.\n",
    "# [0:1] causes he first element of tfidf_matrix_train to me compared to the remaining elemements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in zip(doc_ids, doc_names,cosine_scores[0]):\n",
    "#    print item\n",
    "#print tfidf_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.33953816421943733)\n",
      "(2, 0.27731973415001665)\n",
      "(3, 0.3147974918912641)\n",
      "(5, 0.005848612874140143)\n",
      "(6, 0.35918179627878327)\n",
      "(9, 0.3400911451703303)\n",
      "(10, 0.49137176682524236)\n",
      "(20, 0.44610292359692294)\n",
      "(21, 0.4885678171167488)\n",
      "(22, 0.3344771520596606)\n",
      "(24, 0.3308774772663317)\n",
      "(26, 0.3822253212262135)\n",
      "(27, 0.3551646944788736)\n",
      "(28, 0.4117808317987628)\n",
      "(31, 0.43560931774441364)\n",
      "(32, 0.0014397711311820009)\n",
      "(33, 0.34166055376894616)\n",
      "(34, 0.45663799480356226)\n",
      "(40, 0.34939150462607804)\n",
      "(41, 0.39919423785124203)\n",
      "(42, 1.0000000000000002)\n",
      "(43, 0.4046904643774417)\n",
      "(45, 0.31251774499890667)\n",
      "(46, 0.4847973856249292)\n",
      "(48, 0.394560337477845)\n",
      "(50, 0.24560427753394015)\n",
      "(51, 0.3538230851999409)\n",
      "(52, 0.33649146956161025)\n",
      "(53, 0.34445847705181015)\n",
      "(55, 0.029945918541224636)\n",
      "(60, 0.48544846781148593)\n",
      "(61, 0.0022682513678089766)\n",
      "(66, 0.1597092856757656)\n",
      "(68, 0.37820906225822315)\n",
      "(73, 0.372589569982601)\n",
      "(75, 0.2635726939775015)\n",
      "(76, 0.36096746852901673)\n",
      "(77, 0.4195381003307936)\n",
      "(79, 0.2914022132186483)\n",
      "(81, 0.38707204440788684)\n",
      "(82, 0.37271761631842765)\n",
      "(86, 0.3544744613905831)\n",
      "(87, 0.3909373800298675)\n",
      "(90, 0.4343298273121462)\n",
      "(93, 0.4213466182528321)\n",
      "(94, 0.43582128388452185)\n",
      "(96, 0.1891769023697624)\n",
      "(98, 0.17801574725724698)\n",
      "(99, 0.27463085300421775)\n",
      "(101, 0.3301361549756994)\n",
      "(104, 0.39154351608838217)\n",
      "(106, 0.3561818878084448)\n",
      "(107, 0.4990194507559098)\n",
      "(111, 0.27875409633045006)\n",
      "(112, 0.3406736414636591)\n",
      "(113, 0.4136928406371837)\n",
      "(114, 0.33176156759168446)\n",
      "(115, 0.43102862707575484)\n",
      "(116, 0.4650886755055836)\n",
      "(118, 0.4807949080628007)\n",
      "(120, 0.27484269247645016)\n",
      "(123, 0.0028967681594929398)\n",
      "(128, 0.372216801759811)\n",
      "(129, 0.4245186480678628)\n",
      "(131, 0.38029548602684315)\n",
      "(132, 0.42891639439441676)\n",
      "(134, 0.38915690960828564)\n",
      "(135, 0.4688192713226296)\n",
      "(137, 0.27088999728146745)\n",
      "(142, 0.2979962561218852)\n",
      "(146, 0.357885067689358)\n",
      "(148, 0.32730459464417755)\n",
      "(150, 0.23345861679080332)\n",
      "(153, 0.3392649300945201)\n",
      "(156, 0.036620470667793205)\n",
      "(157, 0.376661069057466)\n",
      "(158, 0.3045758529908299)\n",
      "(160, 0.45097825973205874)\n",
      "(161, 0.4210599457448016)\n",
      "(163, 0.44779354358465073)\n",
      "(164, 0.33302949487303823)\n",
      "(165, 0.31648552710526473)\n",
      "(166, 0.3211243950979008)\n",
      "(167, 0.30620446311715344)\n",
      "(171, 0.1663878149525839)\n",
      "(173, 0.2696646566152115)\n",
      "(176, 0.34913357597297034)\n",
      "(177, 0.35649126906946793)\n",
      "(181, 0.339196501512467)\n",
      "(183, 0.31978230121408185)\n",
      "(188, 0.2855598703216362)\n",
      "(190, 0.30057937545209756)\n",
      "(191, 0.3608322010167495)\n",
      "(192, 0.3416647653556118)\n",
      "(194, 0.2817309049756122)\n",
      "(195, 0.43801257646899866)\n",
      "(196, 0.27912526402952736)\n",
      "(198, 0.44544299115351077)\n",
      "(201, 0.3527513815894619)\n",
      "(202, 0.29904414498295184)\n",
      "(203, 0.39612299401383916)\n",
      "(204, 0.45101578827565575)\n",
      "(205, 0.2687661963425472)\n",
      "(206, 0.3441533513365726)\n",
      "(207, 0.3367200271322163)\n",
      "(212, 0.0009305231546793823)\n",
      "(213, 0.3465620093450305)\n",
      "(214, 0.2239780004440205)\n",
      "(216, 0.3084551332915056)\n",
      "(217, 0.367941155392318)\n",
      "(218, 0.31483154012710757)\n",
      "(221, 0.4425595646510883)\n",
      "(238, 0.3742051664666158)\n",
      "(243, 0.3737681765873049)\n",
      "(245, 0.4228823207257103)\n",
      "(261, 0.34619812017534063)\n",
      "(265, 0.21508220310019224)\n",
      "(268, 0.4529828620425554)\n",
      "(269, 0.46614872065070867)\n",
      "(280, 0.2667093447379234)\n",
      "(289, 0.3465943913386518)\n",
      "(293, 0.3032016052229988)\n",
      "(297, 0.2959734723332219)\n",
      "(310, 0.319064693612293)\n",
      "(340, 0.3123878956190501)\n",
      "(448, 0.28235650138104873)\n",
      "(459, 0.4357777525386483)\n",
      "(460, 0.34943040624953836)\n",
      "(590, 0.2846587833947541)\n",
      "(595, 0.14704572957272422)\n",
      "(596, 0.34778931855629)\n",
      "(597, 0.3778588266191465)\n",
      "(603, 0.3417920044479713)\n",
      "(606, 0.3959342071960769)\n",
      "(608, 0.3423687500790977)\n",
      "(610, 0.2218150047154374)\n",
      "(611, 0.26160353145598353)\n",
      "(616, 0.32411292188309127)\n",
      "(618, 0.2444105213319327)\n",
      "(621, 0.4335713430482217)\n",
      "(796, 0.4073610370611518)\n",
      "(797, 0.30296465808731704)\n",
      "(804, 0.517116562494366)\n",
      "(806, 0.4757360062928344)\n",
      "(812, 0.35127312887884543)\n",
      "(813, 0.32027847163421563)\n",
      "(825, 0.5065805358631539)\n",
      "(826, 0.277868474088159)\n",
      "(828, 0.3137582186002132)\n",
      "(837, 0.3873594519329873)\n",
      "(838, 0.35062549734977533)\n",
      "(839, 0.3480218700732889)\n",
      "(840, 0.3867758580565517)\n",
      "(841, 0.32921667519962083)\n",
      "(842, 0.39757049592851385)\n",
      "(845, 0.4362756646877595)\n",
      "(846, 0.3474702126003504)\n",
      "(981, 0.43679953686568945)\n",
      "(990, 0.37314874477181315)\n",
      "(994, 0.3855130211070016)\n",
      "(996, 0.3317707471850357)\n",
      "(1008, 0.35735662128936785)\n",
      "(1015, 0.3196564373933821)\n",
      "(1022, 0.30324749596772244)\n",
      "(1026, 0.39314918034309027)\n",
      "(1031, 0.40917948763629547)\n",
      "(1033, 0.3685492544283541)\n",
      "(1042, 0.3408884139370867)\n",
      "(1046, 0.30015688612728847)\n",
      "(1047, 0.3736528755249694)\n",
      "(1049, 0.3293646811075731)\n",
      "(1053, 0.3683019289640746)\n",
      "(1054, 0.314899200417931)\n",
      "(1057, 0.40907627038188604)\n",
      "(1060, 0.43599856389497843)\n",
      "(1062, 0.3985888331555297)\n",
      "(1064, 0.27124753579753513)\n",
      "(1069, 0.37941735748308836)\n",
      "(1071, 0.41268983511296903)\n",
      "(1072, 0.3624690413396462)\n",
      "(1073, 0.38719138795414315)\n",
      "(1078, 0.2883470462997005)\n",
      "(1080, 0.41264982752916946)\n",
      "(1082, 0.2666523986989181)\n",
      "(1360, 0.3213541399815663)\n",
      "(1362, 0.2502068070816536)\n",
      "(1363, 0.4323384312698177)\n",
      "(1364, 0.1802628989144834)\n",
      "(1365, 0.22841197837868585)\n",
      "(1366, 0.33446280673471757)\n",
      "(1372, 0.3153282797985363)\n",
      "(1373, 0.3089854413388208)\n",
      "(1375, 0.40199668278051903)\n",
      "(1377, 0.35015198893885024)\n",
      "(1378, 0.2350041909652612)\n",
      "(1379, 0.32916403294417446)\n",
      "(1380, 0.3655670130667366)\n",
      "(1382, 0.45605113674390557)\n",
      "(1835, 0.30314947230969136)\n",
      "(1837, 0.29322321799277107)\n",
      "(1838, 0.3472177135242848)\n",
      "(1839, 0.4122194065332335)\n",
      "(1846, 0.3887649359493303)\n",
      "(1857, 0.47937016624714873)\n"
     ]
    }
   ],
   "source": [
    "doc_no=20 #0-203\n",
    "\n",
    "for item in zip(od.keys(),cosine_scores[doc_no]):\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "\n",
    "x=od.keys()\n",
    "y=cosine_scores[doc_no]\n",
    "\n",
    "# output to HTML file\n",
    "output_file(\"cc_text.html\")\n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"cosine vs doc id\", x_axis_label='x', y_axis_label='y')\n",
    "\n",
    "p.circle(x, y, color=\"blue\", legend=\"text\")\n",
    "\n",
    "# Display plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 12.]\n",
      " [ 0.  0.  1. 18.]]\n",
      "['city=Dubai', 'city=London', 'city=San Francisco', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "measurements = [\n",
    "     {'city': 'Dubai', 'temperature': 33.},\n",
    "     {'city': 'London', 'temperature': 12.},\n",
    "     {'city': 'San Francisco', 'temperature': 18.},\n",
    " ]\n",
    "\n",
    "print vec.fit_transform(measurements).toarray()\n",
    "\n",
    "print vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 0. 1.]\n",
      " [0. 1. 3.]]\n",
      "['bar', 'baz', 'foo']\n"
     ]
    }
   ],
   "source": [
    "D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    " \n",
    "\n",
    "print vec.fit_transform(D).toarray()\n",
    "\n",
    "print vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1.]]\n",
      "['pos+1=PP', 'pos-1=NN', 'pos-2=DT', 'word+1=on', 'word-1=cat', 'word-2=the']\n"
     ]
    }
   ],
   "source": [
    "pos_window = [\n",
    "    {\n",
    "        'word-2': 'the',\n",
    "        'pos-2': 'DT',\n",
    "        'word-1': 'cat',\n",
    "        'pos-1': 'NN',\n",
    "        'word+1': 'on',\n",
    "        'pos+1': 'PP',\n",
    "    },\n",
    "    # in a real application one would extract many such dictionaries\n",
    "]\n",
    "\n",
    "#vec = DictVectorizer()\n",
    "pos_vectorized=vec.fit_transform(pos_window).toarray()\n",
    "\n",
    "print pos_vectorized\n",
    "\n",
    "print vec.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_features(token, part_of_speech):\n",
    "    if token.isdigit():\n",
    "        yield \"numeric\"\n",
    "    else:\n",
    "        yield \"token={}\".format(token.lower())\n",
    "        yield \"token,pos={},{}\".format(token, part_of_speech)\n",
    "    if token[0].isupper():\n",
    "        yield \"uppercase_initial\"\n",
    "    if token.isupper():\n",
    "        yield \"all_uppercase\"\n",
    "    yield \"pos={}\".format(part_of_speech)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "#raw_X = (token_features(tok, pos_tagger(tok)) for tok in pos_vectorized)\n",
    "#hasher = FeatureHasher(input_type='string')\n",
    "#X = hasher.transform(raw_X)\n",
    "for tok in pos_vectorized:\n",
    "    print tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2-venv2",
   "language": "python",
   "name": "py2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
